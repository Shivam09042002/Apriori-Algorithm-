# -*- coding: utf-8 -*-
"""Apriori_Algorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uezSIpEhJVSKNUiEZy2pa1RViW3L0yJb

# Apriori Algorithm
"""

#Importing the Libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Creating a dataframe
df = pd.read_csv('bread basket.csv')

# Displaying first 5 rows of the dataset
df.head()

# Checking the null values
df.isna().sum()

# Determining the unique values of "period_day" column
df['period_day'].value_counts()

# Obtaining the 8 most sold items from the dataset
most_sold=df['Item'].value_counts().head(8)
most_sold

plt.figure(figsize=(12,6))
plt.subplot(1,3,1)
most_sold.plot(kind='line')
plt.title('Items most sold')

plt.subplot(1,3,2)
most_sold.plot(kind='bar')
plt.title('Items most sold')

plt.subplot(1,3,3)
most_sold.plot(kind='pie')
plt.title('Items most sold')

# Converting the item column into list
transaction_list=[]
for i in df['Transaction'].unique():
  tlist=list(set(df[df['Transaction']==i]['Item']))
  if len(tlist)>0:
    transaction_list.append(tlist)
print(len(transaction_list))

# Printing the transaction_list
transaction_list

from mlxtend.preprocessing import TransactionEncoder

# Creating a Transaction Encoder Variable
te = TransactionEncoder()

# Applying fit transform method to the transaction_list
te_ary = te.fit(transaction_list).transform(transaction_list)

te_ary

# Representing the results into pandas dataframe
df = pd.DataFrame(te_ary, columns=te.columns_)

df

from mlxtend.frequent_patterns import apriori

# Setting the minimum support value from the apriori library
freq_itemsets = apriori(df,min_support=0.01, use_colnames=True)

# Displaying the frequent items
freq_itemsets

from mlxtend.frequent_patterns import association_rules

# Applying the association rules on the dataset by having the confidence value %
rules = association_rules(freq_itemsets, metric='confidence', min_threshold=0.5)

rules

# Dropping unwanted column names
rules = rules.drop(columns=['antecedent support','consequent support','lift', 'leverage', 'conviction'])

# Obtaining the final results
rules